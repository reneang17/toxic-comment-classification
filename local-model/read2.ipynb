{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://www.kaggle.com/abhinav2308/pytorch-toxic-comment-solution\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "import spacy\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "my_tok = spacy.load('en')\n",
    "my_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "my_stopwords.update(['wikipedia','article','articles','im','page'])\n",
    "\n",
    "def spacy_tok(x):\n",
    "    x= re.sub(r'[^a-zA-Z\\s]','',x)\n",
    "    x= re.sub(r'[\\n]',' ',x)\n",
    "    return [tok.text for tok in my_tok.tokenizer(x)]\n",
    "\n",
    "\n",
    "\n",
    "TEXT = data.Field(lower=True, tokenize=spacy_tok,eos_token='EOS',stop_words=my_stopwords,include_lengths=True)\n",
    "LABEL = data.Field(sequential=False, \n",
    "                         use_vocab=False, \n",
    "                         pad_token=None, \n",
    "                            unk_token=None)\n",
    "\n",
    "dataFields = [(\"id\", None),\n",
    "                 (\"comment_text\", TEXT), (\"toxic\", LABEL),\n",
    "                 (\"severe_toxic\", LABEL), (\"threat\", LABEL),\n",
    "                 (\"obscene\", LABEL), (\"insult\", LABEL),\n",
    "                 (\"identity_hate\", LABEL)]\n",
    "\n",
    "dataset= data.TabularDataset(path='./data/train.csv', \n",
    "                                            format='csv',\n",
    "                                            fields=dataFields, \n",
    "                                            skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SEED = 1\n",
    "train,val= dataset.split(split_ratio=0.1,random_state = random.seed(SEED))\n",
    "\n",
    "train,val= train.split(split_ratio=0.9,random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 5_000\n",
    "TEXT.build_vocab(train,max_size = MAX_VOCAB_SIZE ,vectors='fasttext.simple.300d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "traindl, valdl = torchtext.data.BucketIterator.splits(datasets=(train, val),\n",
    "                                            batch_sizes=(128,1024),\n",
    "                                            sort_key=lambda x: len(x.comment_text),\n",
    "                                            device=device,\n",
    "                                            sort_within_batch=True\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors= train.fields['comment_text'].vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, dl):\n",
    "        self.dl = dl\n",
    "        self.yFields= ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "        self.x= 'comment_text'\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            X = getattr(batch, self.x)\n",
    "            y = torch.transpose( torch.stack([getattr(batch, y) for y in self.yFields]),0,1)\n",
    "            yield (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self,op_size,n_tokens,pretrained_vectors,nl=2,bidirectional=True,emb_sz=300,n_hiddenUnits=100):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.embeddings= nn.Embedding(n_tokens,emb_sz)\n",
    "        self.embeddings.weight.data.copy_(pretrained_vectors)\n",
    "#         self.embeddings.weight.requires_grad = False\n",
    "\n",
    "        self.n_hidden= n_hiddenUnits\n",
    "    \n",
    "        self.rnn= nn.LSTM(emb_sz,n_hiddenUnits,num_layers=2,bidirectional=True,dropout=0.2)\n",
    "        self.lArr=[]\n",
    "        if bidirectional:\n",
    "            n_hiddenUnits= 2* n_hiddenUnits\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=n_hiddenUnits)\n",
    "        for i in range(nl):\n",
    "            if i==0:\n",
    "                self.lArr.append(nn.Linear(n_hiddenUnits*3,n_hiddenUnits))\n",
    "            else:\n",
    "                self.lArr.append(nn.Linear(n_hiddenUnits,n_hiddenUnits))\n",
    "        self.lArr= nn.ModuleList(self.lArr)\n",
    "        self.l1= nn.Linear(n_hiddenUnits,op_size)\n",
    "        \n",
    "    def forward(self,data,lengths):\n",
    "        bs= data.shape[1]\n",
    "        self.h= self.init_hidden(bs)\n",
    "        embedded= self.embeddings(data)\n",
    "        embedded= nn.Dropout()(embedded)\n",
    "#         embedded = pack_padded_sequence(embedded, torch.as_tensor(lengths))\n",
    "        rnn_out, self.h = self.rnn(embedded, (self.h,self.h))\n",
    "#         rnn_out, lengths = pad_packed_sequence(rnn_out,padding_value=1)\n",
    "        avg_pool= F.adaptive_avg_pool1d(rnn_out.permute(1,2,0),1).view(bs,-1)\n",
    "        max_pool= F.adaptive_max_pool1d(rnn_out.permute(1,2,0),1).view(bs,-1)\n",
    "        ipForLinearLayer= torch.cat([avg_pool,max_pool,rnn_out[-1]],dim=1)\n",
    "        for linearlayer in self.lArr:\n",
    "            outp= linearlayer(ipForLinearLayer)\n",
    "            ipForLinearLayer= self.bn1(F.relu(outp))\n",
    "            ipForLinearLayer= nn.Dropout(p=0.6)(ipForLinearLayer)\n",
    "        outp = self.l1(ipForLinearLayer)\n",
    "        del embedded;del rnn_out;del self.h;\n",
    "        return outp\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros((4,batch_size,self.n_hidden),device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValidationLoss(valdl,model,loss_func):\n",
    "    model.eval() # turn off dropout\n",
    "    runningLoss=0\n",
    "    valid_batch_it = BatchGenerator(valdl)\n",
    "    allPreds= []\n",
    "    allActualPreds= []\n",
    "    with torch.no_grad():\n",
    "        for i,obj in enumerate(valid_batch_it):\n",
    "            obj= ( (obj[0][0],obj[0][1]),obj[1] )\n",
    "            preds = model(obj[0][0],obj[0][1])\n",
    "            loss = loss_func(preds,obj[1].float())\n",
    "            runningLoss+= loss.item()\n",
    "            allPreds.append(preds.detach().cpu().numpy())\n",
    "            allActualPreds.append(obj[1].detach().cpu().numpy())\n",
    "        rocLoss= roc_auc_score(np.vstack(allActualPreds),np.vstack(allPreds))\n",
    "        return runningLoss/len(valid_batch_it),rocLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence,pad_packed_sequence\n",
    "def oneEpoch(lr):\n",
    "    train_batch_it = BatchGenerator(traindl)\n",
    "    opt = optim.Adam(model.parameters(),lr)\n",
    "    runningLoss= 0\n",
    "    allPreds=[]\n",
    "    allActualPreds=[]\n",
    "    for i,obj in enumerate(train_batch_it):\n",
    "        obj= ( (obj[0][0],obj[0][1]),obj[1] )\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        preds = model(obj[0][0],obj[0][1])\n",
    "        loss = loss_func(preds,obj[1].float())\n",
    "        runningLoss+= loss.item()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        allPreds.append(preds.detach().cpu().numpy())\n",
    "        allActualPreds.append(obj[1].detach().cpu().numpy())\n",
    "        del obj;del preds\n",
    "    trainRocLoss= roc_auc_score(np.vstack(allActualPreds),np.vstack(allPreds))\n",
    "    runningLoss= runningLoss/len(train_batch_it)\n",
    "    valLoss,valRocLoss= getValidationLoss(valdl,model,loss_func)\n",
    "    #torch.cuda.empty_cache()\n",
    "    return runningLoss,valLoss,trainRocLoss,valRocLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 27s, sys: 10.2 s, total: 4min 37s\n",
      "Wall time: 55.1 s\n",
      "Epoch - 0\n",
      "Train Loss - 0.7034667967695051 vs Val Loss is 0.6718894839286804\n",
      "Train ROC - 0.5920510337489723 vs Val ROC is 0.571892427772025\n",
      "CPU times: user 4min 23s, sys: 10 s, total: 4min 33s\n",
      "Wall time: 54.1 s\n",
      "Epoch - 1\n",
      "Train Loss - 0.6571796483698145 vs Val Loss is 0.5986789166927338\n",
      "Train ROC - 0.7034781854017438 vs Val ROC is 0.7142862556806359\n",
      "CPU times: user 4min 29s, sys: 10.5 s, total: 4min 40s\n",
      "Wall time: 56.4 s\n",
      "Epoch - 2\n",
      "Train Loss - 0.6016805936804915 vs Val Loss is 0.5383853316307068\n",
      "Train ROC - 0.7574621746884715 vs Val ROC is 0.724277525446309\n",
      "CPU times: user 4min 52s, sys: 11.5 s, total: 5min 3s\n",
      "Wall time: 1min 5s\n",
      "Epoch - 3\n",
      "Train Loss - 0.5341923081241877 vs Val Loss is 0.4770274758338928\n",
      "Train ROC - 0.8054418656175281 vs Val ROC is 0.7830310596252388\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epochs= 4\n",
    "trainLossArr=[]\n",
    "valLossArr=[]\n",
    "rocTrainLoss=[]\n",
    "rocValLoss=[]\n",
    "model= MyModel(6,len(TEXT.vocab),vectors,1)\n",
    "loss_func= torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "for i in range(epochs):\n",
    "    %time tLoss,vLoss,tRocLoss,vRocLoss= oneEpoch(1e-4)\n",
    "    print(f\"Epoch - {i}\")\n",
    "    print(f\"Train Loss - {tLoss} vs Val Loss is {vLoss}\")\n",
    "    print(f\"Train ROC - {tRocLoss} vs Val ROC is {vRocLoss}\")\n",
    "    trainLossArr.append(tLoss)\n",
    "    valLossArr.append(vLoss)\n",
    "    rocTrainLoss.append(tRocLoss)\n",
    "    rocValLoss.append(vRocLoss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
